


<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="AdaptNLP - An easy to use Natural Language Processing library and framework for predicting, training, fine-tuning, and serving up state-of-the-art NLP models.">
      
      
        <link rel="canonical" href="https://github.com/Novetta/adaptnlp/tutorial/advanced-index.html">
      
      
      <link rel="shortcut icon" href="../img/favicon.ico">
      <meta name="generator" content="mkdocs-1.1.2, mkdocs-material-5.5.9">
    
    
      
        <title>Advanced - Intro - AdaptNLP</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.36ee6aaa.min.css">
      
        <link rel="stylesheet" href="../assets/stylesheets/palette.83bccb1f.min.css">
      
      
        
        
        <meta name="theme-color" content="">
      
    
    
    
      
        <link href="https://fonts.gstatic.com" rel="preconnect" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&display=fallback">
        <style>body,input{font-family:"Roboto",-apple-system,BlinkMacSystemFont,Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono",SFMono-Regular,Consolas,Menlo,monospace}</style>
      
    
    
    
      <link rel="stylesheet" href="../css/custom.css">
    
    
      
    
    
  </head>
  
  
    
    
    
    <body dir="ltr" data-md-color-scheme="" data-md-color-primary="800" data-md-color-accent="green">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#install-and-setup" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid" aria-label="Header">
    <a href="https://github.com/Novetta/adaptnlp" title="AdaptNLP" class="md-header-nav__button md-logo" aria-label="AdaptNLP">
      
  <img src="../img/NovettaAdaptNLP-mark-dark-100px.png" alt="logo">

    </a>
    <label class="md-header-nav__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg>
    </label>
    <div class="md-header-nav__title" data-md-component="header-title">
      
        <div class="md-header-nav__ellipsis">
          <span class="md-header-nav__topic md-ellipsis">
            AdaptNLP
          </span>
          <span class="md-header-nav__topic md-ellipsis">
            
              Advanced - Intro
            
          </span>
        </div>
      
    </div>
    
      <label class="md-header-nav__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0116 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 019.5 16 6.5 6.5 0 013 9.5 6.5 6.5 0 019.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
      </label>
      
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" data-md-state="active">
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0116 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 019.5 16 6.5 6.5 0 013 9.5 6.5 6.5 0 019.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
      </label>
      <button type="reset" class="md-search__icon md-icon" aria-label="Clear" data-md-component="search-reset" tabindex="-1">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41L17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg>
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header-nav__source">
        
<a href="https://github.com/Novetta/adaptnlp" title="Go to repository" class="md-source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M439.55 236.05L244 40.45a28.87 28.87 0 00-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 01-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 000 40.81l195.61 195.6a28.86 28.86 0 0040.8 0l194.69-194.69a28.86 28.86 0 000-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    Novetta/adaptnlp
  </div>
</a>
      </div>
    
  </nav>
</header>
    
    <div class="md-container" data-md-component="container">
      
        
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    <nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="https://github.com/Novetta/adaptnlp" title="AdaptNLP" class="md-nav__button md-logo" aria-label="AdaptNLP">
      
  <img src="../img/NovettaAdaptNLP-mark-dark-100px.png" alt="logo">

    </a>
    AdaptNLP
  </label>
  
    <div class="md-nav__source">
      
<a href="https://github.com/Novetta/adaptnlp" title="Go to repository" class="md-source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M439.55 236.05L244 40.45a28.87 28.87 0 00-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 01-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 000 40.81l195.61 195.6a28.86 28.86 0 0040.8 0l194.69-194.69a28.86 28.86 0 000-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    Novetta/adaptnlp
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      


  <li class="md-nav__item">
    <a href="../index.html" title="AdaptNLP Overview" class="md-nav__link">
      AdaptNLP Overview
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-nav__toggle md-toggle" data-md-toggle="nav-2" type="checkbox" id="nav-2">
    
    <label class="md-nav__link" for="nav-2">
      Tutorial - User Guide
      <span class="md-nav__icon md-icon">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg>
      </span>
    </label>
    <nav class="md-nav" aria-label="Tutorial - User Guide" data-md-level="1">
      <label class="md-nav__title" for="nav-2">
        <span class="md-nav__icon md-icon">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
        </span>
        Tutorial - User Guide
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="index.html" title="Tutorial - Intro" class="md-nav__link">
      Tutorial - Intro
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="token-tagging.html" title="Token Tagging" class="md-nav__link">
      Token Tagging
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="sequence-classification.html" title="Sequence Classification" class="md-nav__link">
      Sequence Classification
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="embeddings.html" title="Embeddings" class="md-nav__link">
      Embeddings
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="question-answering.html" title="Question Answering" class="md-nav__link">
      Question Answering
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="summarization.html" title="Summarization" class="md-nav__link">
      Summarization
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="translation.html" title="Translation" class="md-nav__link">
      Translation
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="text-generation.html" title="Text Generation" class="md-nav__link">
      Text Generation
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      

  


  <li class="md-nav__item md-nav__item--active md-nav__item--nested">
    
      <input class="md-nav__toggle md-toggle" data-md-toggle="nav-3" type="checkbox" id="nav-3" checked>
    
    <label class="md-nav__link" for="nav-3">
      Advanced - User Guide
      <span class="md-nav__icon md-icon">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg>
      </span>
    </label>
    <nav class="md-nav" aria-label="Advanced - User Guide" data-md-level="1">
      <label class="md-nav__title" for="nav-3">
        <span class="md-nav__icon md-icon">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
        </span>
        Advanced - User Guide
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          

  


  <li class="md-nav__item md-nav__item--active">
    
    <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
    
    
      <label class="md-nav__link md-nav__link--active" for="__toc">
        Advanced - Intro
        <span class="md-nav__icon md-icon">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 9h14V7H3v2m0 4h14v-2H3v2m0 4h14v-2H3v2m16 0h2v-2h-2v2m0-10v2h2V7h-2m0 6h2v-2h-2v2z"/></svg>
        </span>
      </label>
    
    <a href="advanced-index.html" title="Advanced - Intro" class="md-nav__link md-nav__link--active">
      Advanced - Intro
    </a>
    
      
<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
      </span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#install-and-setup" class="md-nav__link">
    Install and Setup
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#overview-of-training-and-finetuning-capabilities" class="md-nav__link">
    Overview of Training and Finetuning Capabilities
  </a>
  
    <nav class="md-nav" aria-label="Overview of Training and Finetuning Capabilities">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#training-a-sequence-classification-with-sequenceclassifiertrainer" class="md-nav__link">
    Training a Sequence Classification with SequenceClassifierTrainer
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fine-tuning-a-transformers-language-model-with-lmfinetuner" class="md-nav__link">
    Fine-Tuning a Transformers Language Model with LMFineTuner
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
    
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="training-sequence-classification.html" title="Training Sequence Classification" class="md-nav__link">
      Training Sequence Classification
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="fine-tuning-language-model.html" title="Fine Tuning Language Model" class="md-nav__link">
      Fine Tuning Language Model
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../rest.html" title="NLP Services with FastAPI" class="md-nav__link">
      NLP Services with FastAPI
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-nav__toggle md-toggle" data-md-toggle="nav-5" type="checkbox" id="nav-5">
    
    <label class="md-nav__link" for="nav-5">
      Class API
      <span class="md-nav__icon md-icon">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg>
      </span>
    </label>
    <nav class="md-nav" aria-label="Class API" data-md-level="1">
      <label class="md-nav__title" for="nav-5">
        <span class="md-nav__icon md-icon">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
        </span>
        Class API
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-nav__toggle md-toggle" data-md-toggle="nav-5-1" type="checkbox" id="nav-5-1">
    
    <label class="md-nav__link" for="nav-5-1">
      NLP Tasks
      <span class="md-nav__icon md-icon">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg>
      </span>
    </label>
    <nav class="md-nav" aria-label="NLP Tasks" data-md-level="2">
      <label class="md-nav__title" for="nav-5-1">
        <span class="md-nav__icon md-icon">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
        </span>
        NLP Tasks
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../class-api/token-tagger-module.html" title="Token Tagger" class="md-nav__link">
      Token Tagger
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../class-api/sequence-classifier-module.html" title="Sequence Classifier" class="md-nav__link">
      Sequence Classifier
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../class-api/embeddings-module.html" title="Embeddings" class="md-nav__link">
      Embeddings
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../class-api/question-answering-module.html" title="Question Answering" class="md-nav__link">
      Question Answering
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../class-api/summarizer-module.html" title="Summarizer" class="md-nav__link">
      Summarizer
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../class-api/translator-module.html" title="Translator" class="md-nav__link">
      Translator
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-nav__toggle md-toggle" data-md-toggle="nav-5-2" type="checkbox" id="nav-5-2">
    
    <label class="md-nav__link" for="nav-5-2">
      Training and Fine-tuning
      <span class="md-nav__icon md-icon">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg>
      </span>
    </label>
    <nav class="md-nav" aria-label="Training and Fine-tuning" data-md-level="2">
      <label class="md-nav__title" for="nav-5-2">
        <span class="md-nav__icon md-icon">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
        </span>
        Training and Fine-tuning
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../class-api/sequence-classifier-trainer-module.html" title="Sequence Classifier Trainer" class="md-nav__link">
      Sequence Classifier Trainer
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../class-api/language-model-finetuner-module.html" title="Language Model Fine-tuning" class="md-nav__link">
      Language Model Fine-tuning
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../contributing.html" title="Contributing" class="md-nav__link">
      Contributing
    </a>
  </li>

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
      </span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#install-and-setup" class="md-nav__link">
    Install and Setup
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#overview-of-training-and-finetuning-capabilities" class="md-nav__link">
    Overview of Training and Finetuning Capabilities
  </a>
  
    <nav class="md-nav" aria-label="Overview of Training and Finetuning Capabilities">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#training-a-sequence-classification-with-sequenceclassifiertrainer" class="md-nav__link">
    Training a Sequence Classification with SequenceClassifierTrainer
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fine-tuning-a-transformers-language-model-with-lmfinetuner" class="md-nav__link">
    Fine-Tuning a Transformers Language Model with LMFineTuner
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content">
            <article class="md-content__inner md-typeset">
              
                
                
                  
                
                
                  <h1>Advanced - Intro</h1>
                
                <p>This advanced tutorial section goes over using AdaptNLP for training and fine-tuning your own custom NLP models
to get State-of-the-Art results.</p>
<p>You should ideally follow the tutorials along with the provided notebooks in the <code>tutorials</code> directory at the top
level of the AdaptNLP library.</p>
<p>You could also run the code snippets in these tutorials straight through the python interpreter as well.</p>
<h2 id="install-and-setup">Install and Setup<a class="headerlink" href="#install-and-setup" title="Permanent link">&para;</a></h2>
<p>AdaptNLP can be used with or without GPUs.  AdaptNLP will automatically make use of GPU VRAM in environment with
CUDA-compatible NVIDIA GPUs and NVIDIA drivers installed.  GPU-less environments will run AdaptNLP modules fine as well.</p>
<p>You will almost always want to utilize GPUs for training and fine-tuning useful NLP models, so a CUDA-compatible NVIDIA
GPU is a must.</p>
<p>Multi-GPU environments with Apex installed can allow for distributed and/or mixed precision training.</p>
<h2 id="overview-of-training-and-finetuning-capabilities">Overview of Training and Finetuning Capabilities<a class="headerlink" href="#overview-of-training-and-finetuning-capabilities" title="Permanent link">&para;</a></h2>
<p>Simply training a state-of-the-art sequence classification model can be done with AdaptNLP using Flair's sequence 
classification model and trainer with general pre-trained language models.  With encoders providing accurate word 
representations via. models like ALBERT, GPT2, and other transformer models, we can produce accurate NLP task-related
models.</p>
<p>With the concepts of <a href="https://arxiv.org/abs/1801.06146">ULMFiT</a> in mind, AdaptNLP's approach in training downstream
predictive NLP models like sequence classification takes a step further than just utilizing pre-trained
contextualized embeddings.  We are able to effectively fine-tune state-of-the-art language models for useful NLP
tasks on various domain specific data.</p>
<h5 id="training-a-sequence-classification-with-sequenceclassifiertrainer">Training a Sequence Classification with <code>SequenceClassifierTrainer</code><a class="headerlink" href="#training-a-sequence-classification-with-sequenceclassifiertrainer" title="Permanent link">&para;</a></h5>
<div class="codehilite"><pre><span></span><code><span class="kn">from</span> <span class="nn">adaptnlp</span> <span class="kn">import</span> <span class="n">EasyDocumentEmbeddings</span><span class="p">,</span> <span class="n">SequenceClassifierTrainer</span>
<span class="kn">from</span> <span class="nn">flair.datasets</span> <span class="kn">import</span> <span class="n">TREC_6</span>

<span class="c1"># Specify directory for trainer files and model to be downloaded to</span>
<span class="n">OUTPUT_DIR</span> <span class="o">=</span> <span class="s2">&quot;Path/to/model/output/directory&quot;</span> 

<span class="c1"># Load corpus and instantiate AdaptNLP&#39;s `EasyDocumentEmbeddings` with desired embeddings</span>
<span class="n">corpus</span> <span class="o">=</span> <span class="n">TREC_6</span><span class="p">()</span> <span class="c1"># Or path to directory of train.csv, test.csv, dev.csv files at &quot;Path/to/data/directory&quot; </span>
<span class="n">doc_embeddings</span> <span class="o">=</span> <span class="n">EasyDocumentEmbeddings</span><span class="p">(</span><span class="s2">&quot;bert-base-cased&quot;</span><span class="p">,</span> <span class="n">methods</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;rnn&quot;</span><span class="p">])</span>

<span class="c1"># Instantiate the trainer for Sequence Classification with the dataset, embeddings, and mapping of column index of data</span>
<span class="n">sc_trainer</span> <span class="o">=</span> <span class="n">SequenceClassifierTrainer</span><span class="p">(</span><span class="n">corpus</span><span class="o">=</span><span class="n">corpus</span><span class="p">,</span> <span class="n">encoder</span><span class="o">=</span><span class="n">doc_embeddings</span><span class="p">)</span>

<span class="c1"># Find optimal learning rate with automated learning rate finder</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="n">sc_trainer</span><span class="o">.</span><span class="n">find_learning_rate</span><span class="p">(</span><span class="n">output_dir</span><span class="o">=</span><span class="n">OUTPUT_DIR</span><span class="p">)</span>

<span class="c1"># Train the sequence classifier</span>
<span class="n">sc_trainer</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">output_dir</span><span class="o">=</span><span class="n">OUTPUT_DIR</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">,</span> <span class="n">mini_batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">max_epochs</span><span class="o">=</span><span class="mi">150</span><span class="p">)</span>

<span class="c1"># Now load the `EasySequenceClassifier` with the path to your trained model and run inference on your text.</span>
<span class="kn">from</span> <span class="nn">adaptnlp</span> <span class="kn">import</span> <span class="n">EasySequenceClassifier</span>

<span class="n">example_text</span> <span class="o">=</span> <span class="s1">&#39;&#39;&#39;Where was the Queen&#39;s wedding held? &#39;&#39;&#39;</span>

<span class="n">classifier</span> <span class="o">=</span> <span class="n">EasySequenceClassifier</span><span class="p">()</span>

<span class="n">sentences</span> <span class="o">=</span> <span class="n">classifier</span><span class="o">.</span><span class="n">tag_text</span><span class="p">(</span><span class="n">example_text</span><span class="p">,</span> <span class="n">model_name_or_path</span><span class="o">=</span><span class="n">OUTPUT_DIR</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Label output:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">sentences</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">sentence</span><span class="o">.</span><span class="n">labels</span><span class="p">)</span>
</code></pre></div>


<details class = "summary">
<summary>Output</summary>

<div class="codehilite"><pre><span></span><code><span class="mi">2020</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">02</span> <span class="mi">13</span><span class="p">:</span><span class="mi">56</span><span class="p">:</span><span class="mi">09</span><span class="p">,</span><span class="mi">357</span> <span class="p">[</span><span class="sa">b</span><span class="s1">&#39;LOC&#39;</span><span class="p">,</span> <span class="sa">b</span><span class="s1">&#39;DESC&#39;</span><span class="p">,</span> <span class="sa">b</span><span class="s1">&#39;ENTY&#39;</span><span class="p">,</span> <span class="sa">b</span><span class="s1">&#39;HUM&#39;</span><span class="p">,</span> <span class="sa">b</span><span class="s1">&#39;NUM&#39;</span><span class="p">,</span> <span class="sa">b</span><span class="s1">&#39;ABBR&#39;</span><span class="p">]</span>

<span class="p">[</span><span class="mf">1.5135612484362082e-08</span><span class="p">]</span>
<span class="p">[</span><span class="mf">1.8620871366628676e-08</span><span class="p">]</span>
<span class="p">[</span><span class="mf">2.2908676527677733e-08</span><span class="p">]</span>
<span class="p">[</span><span class="mf">2.818382931264454e-08</span><span class="p">]</span>
<span class="p">[</span><span class="mf">3.4673685045253164e-08</span><span class="p">]</span>
<span class="p">[</span><span class="mf">4.265795188015927e-08</span><span class="p">]</span>
<span class="p">[</span><span class="mf">5.2480746024977265e-08</span><span class="p">]</span>
<span class="p">[</span><span class="mf">6.456542290346554e-08</span><span class="p">]</span>
<span class="p">[</span><span class="mf">7.943282347242815e-08</span><span class="p">]</span>
<span class="p">[</span><span class="mf">9.772372209558107e-08</span><span class="p">]</span>
<span class="p">[</span><span class="mf">1.2022644346174127e-07</span><span class="p">]</span>
<span class="p">[</span><span class="mf">1.4791083881682077e-07</span><span class="p">]</span>
<span class="p">[</span><span class="mf">1.819700858609984e-07</span><span class="p">]</span>
<span class="p">[</span><span class="mf">2.2387211385683393e-07</span><span class="p">]</span>
<span class="p">[</span><span class="mf">2.754228703338167e-07</span><span class="p">]</span>
<span class="p">[</span><span class="mf">3.3884415613920264e-07</span><span class="p">]</span>
<span class="p">[</span><span class="mf">4.168693834703353e-07</span><span class="p">]</span>
<span class="p">[</span><span class="mf">5.128613839913649e-07</span><span class="p">]</span>
<span class="p">[</span><span class="mf">6.309573444801935e-07</span><span class="p">]</span>
<span class="p">[</span><span class="mf">7.762471166286916e-07</span><span class="p">]</span>
<span class="p">[</span><span class="mf">9.54992586021436e-07</span><span class="p">]</span>
<span class="p">[</span><span class="mf">1.1748975549395298e-06</span><span class="p">]</span>
<span class="p">[</span><span class="mf">1.4454397707459273e-06</span><span class="p">]</span>
<span class="p">[</span><span class="mf">1.778279410038923e-06</span><span class="p">]</span>
<span class="p">[</span><span class="mf">2.187761623949553e-06</span><span class="p">]</span>
<span class="p">[</span><span class="mf">2.6915348039269168e-06</span><span class="p">]</span>
<span class="p">[</span><span class="mf">3.311311214825913e-06</span><span class="p">]</span>
<span class="p">[</span><span class="mf">4.0738027780411255e-06</span><span class="p">]</span>
<span class="p">[</span><span class="mf">5.011872336272722e-06</span><span class="p">]</span>
<span class="p">[</span><span class="mf">6.165950018614822e-06</span><span class="p">]</span>
<span class="p">[</span><span class="mf">7.585775750291839e-06</span><span class="p">]</span>
<span class="p">[</span><span class="mf">9.332543007969913e-06</span><span class="p">]</span>
<span class="p">[</span><span class="mf">1.1481536214968832e-05</span><span class="p">]</span>
<span class="p">[</span><span class="mf">1.4125375446227536e-05</span><span class="p">]</span>
<span class="p">[</span><span class="mf">1.737800828749375e-05</span><span class="p">]</span>
<span class="p">[</span><span class="mf">2.1379620895022316e-05</span><span class="p">]</span>
<span class="p">[</span><span class="mf">2.6302679918953824e-05</span><span class="p">]</span>
<span class="p">[</span><span class="mf">3.2359365692962836e-05</span><span class="p">]</span>
<span class="p">[</span><span class="mf">3.981071705534974e-05</span><span class="p">]</span>
<span class="p">[</span><span class="mf">4.8977881936844595e-05</span><span class="p">]</span>
<span class="p">[</span><span class="mf">6.025595860743576e-05</span><span class="p">]</span>
<span class="p">[</span><span class="mf">7.413102413009174e-05</span><span class="p">]</span>
<span class="p">[</span><span class="mf">9.120108393559098e-05</span><span class="p">]</span>
<span class="p">[</span><span class="mf">0.00011220184543019637</span><span class="p">]</span>
<span class="p">[</span><span class="mf">0.00013803842646028855</span><span class="p">]</span>
<span class="p">[</span><span class="mf">0.00016982436524617435</span><span class="p">]</span>
<span class="p">[</span><span class="mf">0.00020892961308540387</span><span class="p">]</span>
<span class="p">[</span><span class="mf">0.00025703957827688637</span><span class="p">]</span>
<span class="p">[</span><span class="mf">0.00031622776601683794</span><span class="p">]</span>
<span class="p">[</span><span class="mf">0.0003890451449942807</span><span class="p">]</span>
<span class="p">[</span><span class="mf">0.00047863009232263854</span><span class="p">]</span>
<span class="p">[</span><span class="mf">0.0005888436553555893</span><span class="p">]</span>
<span class="p">[</span><span class="mf">0.0007244359600749906</span><span class="p">]</span>
<span class="p">[</span><span class="mf">0.0008912509381337464</span><span class="p">]</span>
<span class="p">[</span><span class="mf">0.0010964781961431862</span><span class="p">]</span>
<span class="p">[</span><span class="mf">0.001348962882591652</span><span class="p">]</span>
<span class="p">[</span><span class="mf">0.0016595869074375593</span><span class="p">]</span>
<span class="p">[</span><span class="mf">0.002041737944669528</span><span class="p">]</span>
<span class="p">[</span><span class="mf">0.002511886431509579</span><span class="p">]</span>
<span class="p">[</span><span class="mf">0.00309029543251359</span><span class="p">]</span>
<span class="p">[</span><span class="mf">0.003801893963205612</span><span class="p">]</span>
<span class="p">[</span><span class="mf">0.004677351412871982</span><span class="p">]</span>
<span class="p">[</span><span class="mf">0.005754399373371571</span><span class="p">]</span>
<span class="p">[</span><span class="mf">0.007079457843841382</span><span class="p">]</span>
<span class="p">[</span><span class="mf">0.008709635899560813</span><span class="p">]</span>
<span class="p">[</span><span class="mf">0.010715193052376074</span><span class="p">]</span>
<span class="p">[</span><span class="mf">0.013182567385564083</span><span class="p">]</span>
<span class="p">[</span><span class="mf">0.016218100973589285</span><span class="p">]</span>
<span class="p">[</span><span class="mf">0.019952623149688778</span><span class="p">]</span>
<span class="p">[</span><span class="mf">0.024547089156850287</span><span class="p">]</span>
<span class="p">[</span><span class="mf">0.030199517204020147</span><span class="p">]</span>
<span class="p">[</span><span class="mf">0.03715352290971724</span><span class="p">]</span>
<span class="p">[</span><span class="mf">0.0457088189614875</span><span class="p">]</span>
<span class="p">[</span><span class="mf">0.05623413251903491</span><span class="p">]</span>
<span class="p">[</span><span class="mf">0.06918309709189367</span><span class="p">]</span>
<span class="p">[</span><span class="mf">0.08511380382023769</span><span class="p">]</span>
<span class="p">[</span><span class="mf">0.10471285480509002</span><span class="p">]</span>
<span class="p">[</span><span class="mf">0.1288249551693135</span><span class="p">]</span>
<span class="p">[</span><span class="mf">0.1584893192461115</span><span class="p">]</span>
<span class="p">[</span><span class="mf">0.19498445997580477</span><span class="p">]</span>
<span class="p">[</span><span class="mf">0.2398832919019488</span><span class="p">]</span>
<span class="p">[</span><span class="mf">0.29512092266663836</span><span class="p">]</span>
<span class="p">[</span><span class="mf">0.3630780547701011</span><span class="p">]</span>
<span class="p">[</span><span class="mf">0.446683592150963</span><span class="p">]</span>
<span class="p">[</span><span class="mf">0.5495408738576244</span><span class="p">]</span>
<span class="p">[</span><span class="mf">0.6760829753919818</span><span class="p">]</span>
<span class="p">[</span><span class="mf">0.8317637711026711</span><span class="p">]</span>
<span class="p">[</span><span class="mf">1.0232929922807545</span><span class="p">]</span>

<span class="n">Recommended</span> <span class="n">Learning</span> <span class="n">Rate</span> <span class="mf">0.019952623149688778</span>
<span class="mi">2020</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">02</span> <span class="mi">13</span><span class="p">:</span><span class="mi">58</span><span class="p">:</span><span class="mi">10</span><span class="p">,</span><span class="mi">067</span> <span class="o">----------------------------------------------------------------------------------------------------</span>
<span class="mi">2020</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">02</span> <span class="mi">13</span><span class="p">:</span><span class="mi">58</span><span class="p">:</span><span class="mi">10</span><span class="p">,</span><span class="mi">071</span> <span class="n">Model</span><span class="p">:</span> <span class="s2">&quot;TextClassifier(</span>
  <span class="p">(</span><span class="n">document_embeddings</span><span class="p">):</span> <span class="n">DocumentRNNEmbeddings</span><span class="p">(</span>
    <span class="p">(</span><span class="n">embeddings</span><span class="p">):</span> <span class="n">StackedEmbeddings</span><span class="p">(</span>
      <span class="p">(</span><span class="n">list_embedding_0</span><span class="p">):</span> <span class="n">BertEmbeddings</span><span class="p">(</span>
        <span class="p">(</span><span class="n">model</span><span class="p">):</span> <span class="n">BertModel</span><span class="p">(</span>
          <span class="p">(</span><span class="n">embeddings</span><span class="p">):</span> <span class="n">BertEmbeddings</span><span class="p">(</span>
            <span class="p">(</span><span class="n">word_embeddings</span><span class="p">):</span> <span class="n">Embedding</span><span class="p">(</span><span class="mi">28996</span><span class="p">,</span> <span class="mi">768</span><span class="p">,</span> <span class="n">padding_idx</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="p">(</span><span class="n">position_embeddings</span><span class="p">):</span> <span class="n">Embedding</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">768</span><span class="p">)</span>
            <span class="p">(</span><span class="n">token_type_embeddings</span><span class="p">):</span> <span class="n">Embedding</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">768</span><span class="p">)</span>
            <span class="p">(</span><span class="n">LayerNorm</span><span class="p">):</span> <span class="n">LayerNorm</span><span class="p">((</span><span class="mi">768</span><span class="p">,),</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-12</span><span class="p">,</span> <span class="n">elementwise_affine</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="p">(</span><span class="n">dropout</span><span class="p">):</span> <span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
          <span class="p">)</span>
          <span class="p">(</span><span class="n">encoder</span><span class="p">):</span> <span class="n">BertEncoder</span><span class="p">(</span>
            <span class="p">(</span><span class="n">layer</span><span class="p">):</span> <span class="n">ModuleList</span><span class="p">(</span>
              <span class="p">(</span><span class="mi">0</span><span class="p">):</span> <span class="n">BertLayer</span><span class="p">(</span>
                <span class="p">(</span><span class="n">attention</span><span class="p">):</span> <span class="n">BertAttention</span><span class="p">(</span>
                  <span class="p">(</span><span class="bp">self</span><span class="p">):</span> <span class="n">BertSelfAttention</span><span class="p">(</span>
                    <span class="p">(</span><span class="n">query</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                    <span class="p">(</span><span class="n">key</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                    <span class="p">(</span><span class="n">value</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                    <span class="p">(</span><span class="n">dropout</span><span class="p">):</span> <span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
                  <span class="p">)</span>
                  <span class="p">(</span><span class="n">output</span><span class="p">):</span> <span class="n">BertSelfOutput</span><span class="p">(</span>
                    <span class="p">(</span><span class="n">dense</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                    <span class="p">(</span><span class="n">LayerNorm</span><span class="p">):</span> <span class="n">LayerNorm</span><span class="p">((</span><span class="mi">768</span><span class="p">,),</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-12</span><span class="p">,</span> <span class="n">elementwise_affine</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                    <span class="p">(</span><span class="n">dropout</span><span class="p">):</span> <span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
                  <span class="p">)</span>
                <span class="p">)</span>
                <span class="p">(</span><span class="n">intermediate</span><span class="p">):</span> <span class="n">BertIntermediate</span><span class="p">(</span>
                  <span class="p">(</span><span class="n">dense</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">3072</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                <span class="p">)</span>
                <span class="p">(</span><span class="n">output</span><span class="p">):</span> <span class="n">BertOutput</span><span class="p">(</span>
                  <span class="p">(</span><span class="n">dense</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">3072</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                  <span class="p">(</span><span class="n">LayerNorm</span><span class="p">):</span> <span class="n">LayerNorm</span><span class="p">((</span><span class="mi">768</span><span class="p">,),</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-12</span><span class="p">,</span> <span class="n">elementwise_affine</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                  <span class="p">(</span><span class="n">dropout</span><span class="p">):</span> <span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
                <span class="p">)</span>
              <span class="p">)</span>
              <span class="p">(</span><span class="mi">1</span><span class="p">):</span> <span class="n">BertLayer</span><span class="p">(</span>
                <span class="p">(</span><span class="n">attention</span><span class="p">):</span> <span class="n">BertAttention</span><span class="p">(</span>
                  <span class="p">(</span><span class="bp">self</span><span class="p">):</span> <span class="n">BertSelfAttention</span><span class="p">(</span>
                    <span class="p">(</span><span class="n">query</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                    <span class="p">(</span><span class="n">key</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                    <span class="p">(</span><span class="n">value</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                    <span class="p">(</span><span class="n">dropout</span><span class="p">):</span> <span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
                  <span class="p">)</span>
                  <span class="p">(</span><span class="n">output</span><span class="p">):</span> <span class="n">BertSelfOutput</span><span class="p">(</span>
                    <span class="p">(</span><span class="n">dense</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                    <span class="p">(</span><span class="n">LayerNorm</span><span class="p">):</span> <span class="n">LayerNorm</span><span class="p">((</span><span class="mi">768</span><span class="p">,),</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-12</span><span class="p">,</span> <span class="n">elementwise_affine</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                    <span class="p">(</span><span class="n">dropout</span><span class="p">):</span> <span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
                  <span class="p">)</span>
                <span class="p">)</span>
                <span class="p">(</span><span class="n">intermediate</span><span class="p">):</span> <span class="n">BertIntermediate</span><span class="p">(</span>
                  <span class="p">(</span><span class="n">dense</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">3072</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                <span class="p">)</span>
                <span class="p">(</span><span class="n">output</span><span class="p">):</span> <span class="n">BertOutput</span><span class="p">(</span>
                  <span class="p">(</span><span class="n">dense</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">3072</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                  <span class="p">(</span><span class="n">LayerNorm</span><span class="p">):</span> <span class="n">LayerNorm</span><span class="p">((</span><span class="mi">768</span><span class="p">,),</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-12</span><span class="p">,</span> <span class="n">elementwise_affine</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                  <span class="p">(</span><span class="n">dropout</span><span class="p">):</span> <span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
                <span class="p">)</span>
              <span class="p">)</span>
              <span class="p">(</span><span class="mi">2</span><span class="p">):</span> <span class="n">BertLayer</span><span class="p">(</span>
                <span class="p">(</span><span class="n">attention</span><span class="p">):</span> <span class="n">BertAttention</span><span class="p">(</span>
                  <span class="p">(</span><span class="bp">self</span><span class="p">):</span> <span class="n">BertSelfAttention</span><span class="p">(</span>
                    <span class="p">(</span><span class="n">query</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                    <span class="p">(</span><span class="n">key</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                    <span class="p">(</span><span class="n">value</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                    <span class="p">(</span><span class="n">dropout</span><span class="p">):</span> <span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
                  <span class="p">)</span>
                  <span class="p">(</span><span class="n">output</span><span class="p">):</span> <span class="n">BertSelfOutput</span><span class="p">(</span>
                    <span class="p">(</span><span class="n">dense</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                    <span class="p">(</span><span class="n">LayerNorm</span><span class="p">):</span> <span class="n">LayerNorm</span><span class="p">((</span><span class="mi">768</span><span class="p">,),</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-12</span><span class="p">,</span> <span class="n">elementwise_affine</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                    <span class="p">(</span><span class="n">dropout</span><span class="p">):</span> <span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
                  <span class="p">)</span>
                <span class="p">)</span>
                <span class="p">(</span><span class="n">intermediate</span><span class="p">):</span> <span class="n">BertIntermediate</span><span class="p">(</span>
                  <span class="p">(</span><span class="n">dense</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">3072</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                <span class="p">)</span>
                <span class="p">(</span><span class="n">output</span><span class="p">):</span> <span class="n">BertOutput</span><span class="p">(</span>
                  <span class="p">(</span><span class="n">dense</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">3072</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                  <span class="p">(</span><span class="n">LayerNorm</span><span class="p">):</span> <span class="n">LayerNorm</span><span class="p">((</span><span class="mi">768</span><span class="p">,),</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-12</span><span class="p">,</span> <span class="n">elementwise_affine</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                  <span class="p">(</span><span class="n">dropout</span><span class="p">):</span> <span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
                <span class="p">)</span>
              <span class="p">)</span>
              <span class="p">(</span><span class="mi">3</span><span class="p">):</span> <span class="n">BertLayer</span><span class="p">(</span>
                <span class="p">(</span><span class="n">attention</span><span class="p">):</span> <span class="n">BertAttention</span><span class="p">(</span>
                  <span class="p">(</span><span class="bp">self</span><span class="p">):</span> <span class="n">BertSelfAttention</span><span class="p">(</span>
                    <span class="p">(</span><span class="n">query</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                    <span class="p">(</span><span class="n">key</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                    <span class="p">(</span><span class="n">value</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                    <span class="p">(</span><span class="n">dropout</span><span class="p">):</span> <span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
                  <span class="p">)</span>
                  <span class="p">(</span><span class="n">output</span><span class="p">):</span> <span class="n">BertSelfOutput</span><span class="p">(</span>
                    <span class="p">(</span><span class="n">dense</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                    <span class="p">(</span><span class="n">LayerNorm</span><span class="p">):</span> <span class="n">LayerNorm</span><span class="p">((</span><span class="mi">768</span><span class="p">,),</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-12</span><span class="p">,</span> <span class="n">elementwise_affine</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                    <span class="p">(</span><span class="n">dropout</span><span class="p">):</span> <span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
                  <span class="p">)</span>
                <span class="p">)</span>
                <span class="p">(</span><span class="n">intermediate</span><span class="p">):</span> <span class="n">BertIntermediate</span><span class="p">(</span>
                  <span class="p">(</span><span class="n">dense</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">3072</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                <span class="p">)</span>
                <span class="p">(</span><span class="n">output</span><span class="p">):</span> <span class="n">BertOutput</span><span class="p">(</span>
                  <span class="p">(</span><span class="n">dense</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">3072</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                  <span class="p">(</span><span class="n">LayerNorm</span><span class="p">):</span> <span class="n">LayerNorm</span><span class="p">((</span><span class="mi">768</span><span class="p">,),</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-12</span><span class="p">,</span> <span class="n">elementwise_affine</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                  <span class="p">(</span><span class="n">dropout</span><span class="p">):</span> <span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
                <span class="p">)</span>
              <span class="p">)</span>
              <span class="p">(</span><span class="mi">4</span><span class="p">):</span> <span class="n">BertLayer</span><span class="p">(</span>
                <span class="p">(</span><span class="n">attention</span><span class="p">):</span> <span class="n">BertAttention</span><span class="p">(</span>
                  <span class="p">(</span><span class="bp">self</span><span class="p">):</span> <span class="n">BertSelfAttention</span><span class="p">(</span>
                    <span class="p">(</span><span class="n">query</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                    <span class="p">(</span><span class="n">key</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                    <span class="p">(</span><span class="n">value</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                    <span class="p">(</span><span class="n">dropout</span><span class="p">):</span> <span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
                  <span class="p">)</span>
                  <span class="p">(</span><span class="n">output</span><span class="p">):</span> <span class="n">BertSelfOutput</span><span class="p">(</span>
                    <span class="p">(</span><span class="n">dense</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                    <span class="p">(</span><span class="n">LayerNorm</span><span class="p">):</span> <span class="n">LayerNorm</span><span class="p">((</span><span class="mi">768</span><span class="p">,),</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-12</span><span class="p">,</span> <span class="n">elementwise_affine</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                    <span class="p">(</span><span class="n">dropout</span><span class="p">):</span> <span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
                  <span class="p">)</span>
                <span class="p">)</span>
                <span class="p">(</span><span class="n">intermediate</span><span class="p">):</span> <span class="n">BertIntermediate</span><span class="p">(</span>
                  <span class="p">(</span><span class="n">dense</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">3072</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                <span class="p">)</span>
                <span class="p">(</span><span class="n">output</span><span class="p">):</span> <span class="n">BertOutput</span><span class="p">(</span>
                  <span class="p">(</span><span class="n">dense</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">3072</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                  <span class="p">(</span><span class="n">LayerNorm</span><span class="p">):</span> <span class="n">LayerNorm</span><span class="p">((</span><span class="mi">768</span><span class="p">,),</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-12</span><span class="p">,</span> <span class="n">elementwise_affine</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                  <span class="p">(</span><span class="n">dropout</span><span class="p">):</span> <span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
                <span class="p">)</span>
              <span class="p">)</span>
              <span class="p">(</span><span class="mi">5</span><span class="p">):</span> <span class="n">BertLayer</span><span class="p">(</span>
                <span class="p">(</span><span class="n">attention</span><span class="p">):</span> <span class="n">BertAttention</span><span class="p">(</span>
                  <span class="p">(</span><span class="bp">self</span><span class="p">):</span> <span class="n">BertSelfAttention</span><span class="p">(</span>
                    <span class="p">(</span><span class="n">query</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                    <span class="p">(</span><span class="n">key</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                    <span class="p">(</span><span class="n">value</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                    <span class="p">(</span><span class="n">dropout</span><span class="p">):</span> <span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
                  <span class="p">)</span>
                  <span class="p">(</span><span class="n">output</span><span class="p">):</span> <span class="n">BertSelfOutput</span><span class="p">(</span>
                    <span class="p">(</span><span class="n">dense</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                    <span class="p">(</span><span class="n">LayerNorm</span><span class="p">):</span> <span class="n">LayerNorm</span><span class="p">((</span><span class="mi">768</span><span class="p">,),</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-12</span><span class="p">,</span> <span class="n">elementwise_affine</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                    <span class="p">(</span><span class="n">dropout</span><span class="p">):</span> <span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
                  <span class="p">)</span>
                <span class="p">)</span>
                <span class="p">(</span><span class="n">intermediate</span><span class="p">):</span> <span class="n">BertIntermediate</span><span class="p">(</span>
                  <span class="p">(</span><span class="n">dense</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">3072</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                <span class="p">)</span>
                <span class="p">(</span><span class="n">output</span><span class="p">):</span> <span class="n">BertOutput</span><span class="p">(</span>
                  <span class="p">(</span><span class="n">dense</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">3072</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                  <span class="p">(</span><span class="n">LayerNorm</span><span class="p">):</span> <span class="n">LayerNorm</span><span class="p">((</span><span class="mi">768</span><span class="p">,),</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-12</span><span class="p">,</span> <span class="n">elementwise_affine</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                  <span class="p">(</span><span class="n">dropout</span><span class="p">):</span> <span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
                <span class="p">)</span>
              <span class="p">)</span>
              <span class="p">(</span><span class="mi">6</span><span class="p">):</span> <span class="n">BertLayer</span><span class="p">(</span>
                <span class="p">(</span><span class="n">attention</span><span class="p">):</span> <span class="n">BertAttention</span><span class="p">(</span>
                  <span class="p">(</span><span class="bp">self</span><span class="p">):</span> <span class="n">BertSelfAttention</span><span class="p">(</span>
                    <span class="p">(</span><span class="n">query</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                    <span class="p">(</span><span class="n">key</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                    <span class="p">(</span><span class="n">value</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                    <span class="p">(</span><span class="n">dropout</span><span class="p">):</span> <span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
                  <span class="p">)</span>
                  <span class="p">(</span><span class="n">output</span><span class="p">):</span> <span class="n">BertSelfOutput</span><span class="p">(</span>
                    <span class="p">(</span><span class="n">dense</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                    <span class="p">(</span><span class="n">LayerNorm</span><span class="p">):</span> <span class="n">LayerNorm</span><span class="p">((</span><span class="mi">768</span><span class="p">,),</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-12</span><span class="p">,</span> <span class="n">elementwise_affine</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                    <span class="p">(</span><span class="n">dropout</span><span class="p">):</span> <span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
                  <span class="p">)</span>
                <span class="p">)</span>
                <span class="p">(</span><span class="n">intermediate</span><span class="p">):</span> <span class="n">BertIntermediate</span><span class="p">(</span>
                  <span class="p">(</span><span class="n">dense</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">3072</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                <span class="p">)</span>
                <span class="p">(</span><span class="n">output</span><span class="p">):</span> <span class="n">BertOutput</span><span class="p">(</span>
                  <span class="p">(</span><span class="n">dense</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">3072</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                  <span class="p">(</span><span class="n">LayerNorm</span><span class="p">):</span> <span class="n">LayerNorm</span><span class="p">((</span><span class="mi">768</span><span class="p">,),</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-12</span><span class="p">,</span> <span class="n">elementwise_affine</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                  <span class="p">(</span><span class="n">dropout</span><span class="p">):</span> <span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
                <span class="p">)</span>
              <span class="p">)</span>
              <span class="p">(</span><span class="mi">7</span><span class="p">):</span> <span class="n">BertLayer</span><span class="p">(</span>
                <span class="p">(</span><span class="n">attention</span><span class="p">):</span> <span class="n">BertAttention</span><span class="p">(</span>
                  <span class="p">(</span><span class="bp">self</span><span class="p">):</span> <span class="n">BertSelfAttention</span><span class="p">(</span>
                    <span class="p">(</span><span class="n">query</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                    <span class="p">(</span><span class="n">key</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                    <span class="p">(</span><span class="n">value</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                    <span class="p">(</span><span class="n">dropout</span><span class="p">):</span> <span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
                  <span class="p">)</span>
                  <span class="p">(</span><span class="n">output</span><span class="p">):</span> <span class="n">BertSelfOutput</span><span class="p">(</span>
                    <span class="p">(</span><span class="n">dense</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                    <span class="p">(</span><span class="n">LayerNorm</span><span class="p">):</span> <span class="n">LayerNorm</span><span class="p">((</span><span class="mi">768</span><span class="p">,),</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-12</span><span class="p">,</span> <span class="n">elementwise_affine</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                    <span class="p">(</span><span class="n">dropout</span><span class="p">):</span> <span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
                  <span class="p">)</span>
                <span class="p">)</span>
                <span class="p">(</span><span class="n">intermediate</span><span class="p">):</span> <span class="n">BertIntermediate</span><span class="p">(</span>
                  <span class="p">(</span><span class="n">dense</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">3072</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                <span class="p">)</span>
                <span class="p">(</span><span class="n">output</span><span class="p">):</span> <span class="n">BertOutput</span><span class="p">(</span>
                  <span class="p">(</span><span class="n">dense</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">3072</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                  <span class="p">(</span><span class="n">LayerNorm</span><span class="p">):</span> <span class="n">LayerNorm</span><span class="p">((</span><span class="mi">768</span><span class="p">,),</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-12</span><span class="p">,</span> <span class="n">elementwise_affine</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                  <span class="p">(</span><span class="n">dropout</span><span class="p">):</span> <span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
                <span class="p">)</span>
              <span class="p">)</span>
              <span class="p">(</span><span class="mi">8</span><span class="p">):</span> <span class="n">BertLayer</span><span class="p">(</span>
                <span class="p">(</span><span class="n">attention</span><span class="p">):</span> <span class="n">BertAttention</span><span class="p">(</span>
                  <span class="p">(</span><span class="bp">self</span><span class="p">):</span> <span class="n">BertSelfAttention</span><span class="p">(</span>
                    <span class="p">(</span><span class="n">query</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                    <span class="p">(</span><span class="n">key</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                    <span class="p">(</span><span class="n">value</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                    <span class="p">(</span><span class="n">dropout</span><span class="p">):</span> <span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
                  <span class="p">)</span>
                  <span class="p">(</span><span class="n">output</span><span class="p">):</span> <span class="n">BertSelfOutput</span><span class="p">(</span>
                    <span class="p">(</span><span class="n">dense</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                    <span class="p">(</span><span class="n">LayerNorm</span><span class="p">):</span> <span class="n">LayerNorm</span><span class="p">((</span><span class="mi">768</span><span class="p">,),</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-12</span><span class="p">,</span> <span class="n">elementwise_affine</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                    <span class="p">(</span><span class="n">dropout</span><span class="p">):</span> <span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
                  <span class="p">)</span>
                <span class="p">)</span>
                <span class="p">(</span><span class="n">intermediate</span><span class="p">):</span> <span class="n">BertIntermediate</span><span class="p">(</span>
                  <span class="p">(</span><span class="n">dense</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">3072</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                <span class="p">)</span>
                <span class="p">(</span><span class="n">output</span><span class="p">):</span> <span class="n">BertOutput</span><span class="p">(</span>
                  <span class="p">(</span><span class="n">dense</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">3072</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                  <span class="p">(</span><span class="n">LayerNorm</span><span class="p">):</span> <span class="n">LayerNorm</span><span class="p">((</span><span class="mi">768</span><span class="p">,),</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-12</span><span class="p">,</span> <span class="n">elementwise_affine</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                  <span class="p">(</span><span class="n">dropout</span><span class="p">):</span> <span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
                <span class="p">)</span>
              <span class="p">)</span>
              <span class="p">(</span><span class="mi">9</span><span class="p">):</span> <span class="n">BertLayer</span><span class="p">(</span>
                <span class="p">(</span><span class="n">attention</span><span class="p">):</span> <span class="n">BertAttention</span><span class="p">(</span>
                  <span class="p">(</span><span class="bp">self</span><span class="p">):</span> <span class="n">BertSelfAttention</span><span class="p">(</span>
                    <span class="p">(</span><span class="n">query</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                    <span class="p">(</span><span class="n">key</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                    <span class="p">(</span><span class="n">value</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                    <span class="p">(</span><span class="n">dropout</span><span class="p">):</span> <span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
                  <span class="p">)</span>
                  <span class="p">(</span><span class="n">output</span><span class="p">):</span> <span class="n">BertSelfOutput</span><span class="p">(</span>
                    <span class="p">(</span><span class="n">dense</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                    <span class="p">(</span><span class="n">LayerNorm</span><span class="p">):</span> <span class="n">LayerNorm</span><span class="p">((</span><span class="mi">768</span><span class="p">,),</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-12</span><span class="p">,</span> <span class="n">elementwise_affine</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                    <span class="p">(</span><span class="n">dropout</span><span class="p">):</span> <span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
                  <span class="p">)</span>
                <span class="p">)</span>
                <span class="p">(</span><span class="n">intermediate</span><span class="p">):</span> <span class="n">BertIntermediate</span><span class="p">(</span>
                  <span class="p">(</span><span class="n">dense</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">3072</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                <span class="p">)</span>
                <span class="p">(</span><span class="n">output</span><span class="p">):</span> <span class="n">BertOutput</span><span class="p">(</span>
                  <span class="p">(</span><span class="n">dense</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">3072</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                  <span class="p">(</span><span class="n">LayerNorm</span><span class="p">):</span> <span class="n">LayerNorm</span><span class="p">((</span><span class="mi">768</span><span class="p">,),</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-12</span><span class="p">,</span> <span class="n">elementwise_affine</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                  <span class="p">(</span><span class="n">dropout</span><span class="p">):</span> <span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
                <span class="p">)</span>
              <span class="p">)</span>
              <span class="p">(</span><span class="mi">10</span><span class="p">):</span> <span class="n">BertLayer</span><span class="p">(</span>
                <span class="p">(</span><span class="n">attention</span><span class="p">):</span> <span class="n">BertAttention</span><span class="p">(</span>
                  <span class="p">(</span><span class="bp">self</span><span class="p">):</span> <span class="n">BertSelfAttention</span><span class="p">(</span>
                    <span class="p">(</span><span class="n">query</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                    <span class="p">(</span><span class="n">key</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                    <span class="p">(</span><span class="n">value</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                    <span class="p">(</span><span class="n">dropout</span><span class="p">):</span> <span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
                  <span class="p">)</span>
                  <span class="p">(</span><span class="n">output</span><span class="p">):</span> <span class="n">BertSelfOutput</span><span class="p">(</span>
                    <span class="p">(</span><span class="n">dense</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                    <span class="p">(</span><span class="n">LayerNorm</span><span class="p">):</span> <span class="n">LayerNorm</span><span class="p">((</span><span class="mi">768</span><span class="p">,),</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-12</span><span class="p">,</span> <span class="n">elementwise_affine</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                    <span class="p">(</span><span class="n">dropout</span><span class="p">):</span> <span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
                  <span class="p">)</span>
                <span class="p">)</span>
                <span class="p">(</span><span class="n">intermediate</span><span class="p">):</span> <span class="n">BertIntermediate</span><span class="p">(</span>
                  <span class="p">(</span><span class="n">dense</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">3072</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                <span class="p">)</span>
                <span class="p">(</span><span class="n">output</span><span class="p">):</span> <span class="n">BertOutput</span><span class="p">(</span>
                  <span class="p">(</span><span class="n">dense</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">3072</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                  <span class="p">(</span><span class="n">LayerNorm</span><span class="p">):</span> <span class="n">LayerNorm</span><span class="p">((</span><span class="mi">768</span><span class="p">,),</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-12</span><span class="p">,</span> <span class="n">elementwise_affine</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                  <span class="p">(</span><span class="n">dropout</span><span class="p">):</span> <span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
                <span class="p">)</span>
              <span class="p">)</span>
              <span class="p">(</span><span class="mi">11</span><span class="p">):</span> <span class="n">BertLayer</span><span class="p">(</span>
                <span class="p">(</span><span class="n">attention</span><span class="p">):</span> <span class="n">BertAttention</span><span class="p">(</span>
                  <span class="p">(</span><span class="bp">self</span><span class="p">):</span> <span class="n">BertSelfAttention</span><span class="p">(</span>
                    <span class="p">(</span><span class="n">query</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                    <span class="p">(</span><span class="n">key</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                    <span class="p">(</span><span class="n">value</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                    <span class="p">(</span><span class="n">dropout</span><span class="p">):</span> <span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
                  <span class="p">)</span>
                  <span class="p">(</span><span class="n">output</span><span class="p">):</span> <span class="n">BertSelfOutput</span><span class="p">(</span>
                    <span class="p">(</span><span class="n">dense</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                    <span class="p">(</span><span class="n">LayerNorm</span><span class="p">):</span> <span class="n">LayerNorm</span><span class="p">((</span><span class="mi">768</span><span class="p">,),</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-12</span><span class="p">,</span> <span class="n">elementwise_affine</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                    <span class="p">(</span><span class="n">dropout</span><span class="p">):</span> <span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
                  <span class="p">)</span>
                <span class="p">)</span>
                <span class="p">(</span><span class="n">intermediate</span><span class="p">):</span> <span class="n">BertIntermediate</span><span class="p">(</span>
                  <span class="p">(</span><span class="n">dense</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">3072</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                <span class="p">)</span>
                <span class="p">(</span><span class="n">output</span><span class="p">):</span> <span class="n">BertOutput</span><span class="p">(</span>
                  <span class="p">(</span><span class="n">dense</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">3072</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                  <span class="p">(</span><span class="n">LayerNorm</span><span class="p">):</span> <span class="n">LayerNorm</span><span class="p">((</span><span class="mi">768</span><span class="p">,),</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-12</span><span class="p">,</span> <span class="n">elementwise_affine</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                  <span class="p">(</span><span class="n">dropout</span><span class="p">):</span> <span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
                <span class="p">)</span>
              <span class="p">)</span>
            <span class="p">)</span>
          <span class="p">)</span>
          <span class="p">(</span><span class="n">pooler</span><span class="p">):</span> <span class="n">BertPooler</span><span class="p">(</span>
            <span class="p">(</span><span class="n">dense</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="p">(</span><span class="n">activation</span><span class="p">):</span> <span class="n">Tanh</span><span class="p">()</span>
          <span class="p">)</span>
        <span class="p">)</span>
      <span class="p">)</span>
    <span class="p">)</span>
    <span class="p">(</span><span class="n">word_reprojection_map</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">3072</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="p">(</span><span class="n">rnn</span><span class="p">):</span> <span class="n">GRU</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="p">(</span><span class="n">dropout</span><span class="p">):</span> <span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
  <span class="p">)</span>
  <span class="p">(</span><span class="n">decoder</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
  <span class="p">(</span><span class="n">loss_function</span><span class="p">):</span> <span class="n">CrossEntropyLoss</span><span class="p">()</span>
  <span class="p">(</span><span class="n">beta</span><span class="p">):</span> <span class="mf">1.0</span>
  <span class="p">(</span><span class="n">weights</span><span class="p">):</span> <span class="kc">None</span>
  <span class="p">(</span><span class="n">weight_tensor</span><span class="p">)</span> <span class="kc">None</span>
<span class="p">)</span><span class="s2">&quot;</span>
<span class="mi">2020</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">02</span> <span class="mi">13</span><span class="p">:</span><span class="mi">58</span><span class="p">:</span><span class="mi">10</span><span class="p">,</span><span class="mi">071</span> <span class="o">----------------------------------------------------------------------------------------------------</span>
<span class="mi">2020</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">02</span> <span class="mi">13</span><span class="p">:</span><span class="mi">58</span><span class="p">:</span><span class="mi">10</span><span class="p">,</span><span class="mi">073</span> <span class="n">Corpus</span><span class="p">:</span> <span class="s2">&quot;Corpus: 4907 train + 545 dev + 500 test sentences&quot;</span>
<span class="mi">2020</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">02</span> <span class="mi">13</span><span class="p">:</span><span class="mi">58</span><span class="p">:</span><span class="mi">10</span><span class="p">,</span><span class="mi">074</span> <span class="o">----------------------------------------------------------------------------------------------------</span>
<span class="mi">2020</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">02</span> <span class="mi">13</span><span class="p">:</span><span class="mi">58</span><span class="p">:</span><span class="mi">10</span><span class="p">,</span><span class="mi">074</span> <span class="n">Parameters</span><span class="p">:</span>
<span class="mi">2020</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">02</span> <span class="mi">13</span><span class="p">:</span><span class="mi">58</span><span class="p">:</span><span class="mi">10</span><span class="p">,</span><span class="mi">075</span>  <span class="o">-</span> <span class="n">learning_rate</span><span class="p">:</span> <span class="s2">&quot;0.019952623149688778&quot;</span>
<span class="mi">2020</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">02</span> <span class="mi">13</span><span class="p">:</span><span class="mi">58</span><span class="p">:</span><span class="mi">10</span><span class="p">,</span><span class="mi">076</span>  <span class="o">-</span> <span class="n">mini_batch_size</span><span class="p">:</span> <span class="s2">&quot;32&quot;</span>
<span class="mi">2020</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">02</span> <span class="mi">13</span><span class="p">:</span><span class="mi">58</span><span class="p">:</span><span class="mi">10</span><span class="p">,</span><span class="mi">077</span>  <span class="o">-</span> <span class="n">patience</span><span class="p">:</span> <span class="s2">&quot;5&quot;</span>
<span class="mi">2020</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">02</span> <span class="mi">13</span><span class="p">:</span><span class="mi">58</span><span class="p">:</span><span class="mi">10</span><span class="p">,</span><span class="mi">077</span>  <span class="o">-</span> <span class="n">anneal_factor</span><span class="p">:</span> <span class="s2">&quot;0.5&quot;</span>
<span class="mi">2020</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">02</span> <span class="mi">13</span><span class="p">:</span><span class="mi">58</span><span class="p">:</span><span class="mi">10</span><span class="p">,</span><span class="mi">080</span>  <span class="o">-</span> <span class="n">max_epochs</span><span class="p">:</span> <span class="s2">&quot;150&quot;</span>
<span class="mi">2020</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">02</span> <span class="mi">13</span><span class="p">:</span><span class="mi">58</span><span class="p">:</span><span class="mi">10</span><span class="p">,</span><span class="mi">081</span>  <span class="o">-</span> <span class="n">shuffle</span><span class="p">:</span> <span class="s2">&quot;True&quot;</span>
<span class="mi">2020</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">02</span> <span class="mi">13</span><span class="p">:</span><span class="mi">58</span><span class="p">:</span><span class="mi">10</span><span class="p">,</span><span class="mi">081</span>  <span class="o">-</span> <span class="n">train_with_dev</span><span class="p">:</span> <span class="s2">&quot;False&quot;</span>
<span class="mi">2020</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">02</span> <span class="mi">13</span><span class="p">:</span><span class="mi">58</span><span class="p">:</span><span class="mi">10</span><span class="p">,</span><span class="mi">082</span>  <span class="o">-</span> <span class="n">batch_growth_annealing</span><span class="p">:</span> <span class="s2">&quot;False&quot;</span>
<span class="mi">2020</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">02</span> <span class="mi">13</span><span class="p">:</span><span class="mi">58</span><span class="p">:</span><span class="mi">10</span><span class="p">,</span><span class="mi">083</span> <span class="o">----------------------------------------------------------------------------------------------------</span>
<span class="mi">2020</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">02</span> <span class="mi">13</span><span class="p">:</span><span class="mi">58</span><span class="p">:</span><span class="mi">10</span><span class="p">,</span><span class="mi">084</span> <span class="n">Model</span> <span class="n">training</span> <span class="n">base</span> <span class="n">path</span><span class="p">:</span> <span class="s2">&quot;data-volume-1&quot;</span>
<span class="mi">2020</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">02</span> <span class="mi">13</span><span class="p">:</span><span class="mi">58</span><span class="p">:</span><span class="mi">10</span><span class="p">,</span><span class="mi">084</span> <span class="o">----------------------------------------------------------------------------------------------------</span>
<span class="mi">2020</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">02</span> <span class="mi">13</span><span class="p">:</span><span class="mi">58</span><span class="p">:</span><span class="mi">10</span><span class="p">,</span><span class="mi">087</span> <span class="n">Device</span><span class="p">:</span> <span class="n">cpu</span>
<span class="mi">2020</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">02</span> <span class="mi">13</span><span class="p">:</span><span class="mi">58</span><span class="p">:</span><span class="mi">10</span><span class="p">,</span><span class="mi">088</span> <span class="o">----------------------------------------------------------------------------------------------------</span>
<span class="mi">2020</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">02</span> <span class="mi">13</span><span class="p">:</span><span class="mi">58</span><span class="p">:</span><span class="mi">10</span><span class="p">,</span><span class="mi">088</span> <span class="n">Embeddings</span> <span class="n">storage</span> <span class="n">mode</span><span class="p">:</span> <span class="n">cpu</span>
<span class="mi">2020</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">02</span> <span class="mi">13</span><span class="p">:</span><span class="mi">58</span><span class="p">:</span><span class="mi">10</span><span class="p">,</span><span class="mi">091</span> <span class="o">----------------------------------------------------------------------------------------------------</span>
<span class="mi">2020</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">02</span> <span class="mi">13</span><span class="p">:</span><span class="mi">58</span><span class="p">:</span><span class="mi">32</span><span class="p">,</span><span class="mi">513</span> <span class="n">epoch</span> <span class="mi">1</span> <span class="o">-</span> <span class="nb">iter</span> <span class="mi">15</span><span class="o">/</span><span class="mi">154</span> <span class="o">-</span> <span class="n">loss</span> <span class="mf">2.13271559</span> <span class="o">-</span> <span class="n">samples</span><span class="o">/</span><span class="n">sec</span><span class="p">:</span> <span class="mf">21.61</span>
<span class="mi">2020</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">02</span> <span class="mi">13</span><span class="p">:</span><span class="mi">58</span><span class="p">:</span><span class="mi">53</span><span class="p">,</span><span class="mi">034</span> <span class="n">epoch</span> <span class="mi">1</span> <span class="o">-</span> <span class="nb">iter</span> <span class="mi">30</span><span class="o">/</span><span class="mi">154</span> <span class="o">-</span> <span class="n">loss</span> <span class="mf">2.05371269</span> <span class="o">-</span> <span class="n">samples</span><span class="o">/</span><span class="n">sec</span><span class="p">:</span> <span class="mf">23.78</span>
<span class="mi">2020</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">02</span> <span class="mi">13</span><span class="p">:</span><span class="mi">59</span><span class="p">:</span><span class="mi">12</span><span class="p">,</span><span class="mi">643</span> <span class="n">epoch</span> <span class="mi">1</span> <span class="o">-</span> <span class="nb">iter</span> <span class="mi">45</span><span class="o">/</span><span class="mi">154</span> <span class="o">-</span> <span class="n">loss</span> <span class="mf">2.01068912</span> <span class="o">-</span> <span class="n">samples</span><span class="o">/</span><span class="n">sec</span><span class="p">:</span> <span class="mf">24.63</span>
<span class="mi">2020</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">02</span> <span class="mi">13</span><span class="p">:</span><span class="mi">59</span><span class="p">:</span><span class="mi">33</span><span class="p">,</span><span class="mi">185</span> <span class="n">epoch</span> <span class="mi">1</span> <span class="o">-</span> <span class="nb">iter</span> <span class="mi">60</span><span class="o">/</span><span class="mi">154</span> <span class="o">-</span> <span class="n">loss</span> <span class="mf">2.00240319</span> <span class="o">-</span> <span class="n">samples</span><span class="o">/</span><span class="n">sec</span><span class="p">:</span> <span class="mf">23.50</span>
<span class="mi">2020</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">02</span> <span class="mi">13</span><span class="p">:</span><span class="mi">59</span><span class="p">:</span><span class="mi">52</span><span class="p">,</span><span class="mi">275</span> <span class="n">epoch</span> <span class="mi">1</span> <span class="o">-</span> <span class="nb">iter</span> <span class="mi">75</span><span class="o">/</span><span class="mi">154</span> <span class="o">-</span> <span class="n">loss</span> <span class="mf">1.97219250</span> <span class="o">-</span> <span class="n">samples</span><span class="o">/</span><span class="n">sec</span><span class="p">:</span> <span class="mf">25.29</span>
<span class="mi">2020</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">02</span> <span class="mi">14</span><span class="p">:</span><span class="mi">00</span><span class="p">:</span><span class="mi">11</span><span class="p">,</span><span class="mi">458</span> <span class="n">epoch</span> <span class="mi">1</span> <span class="o">-</span> <span class="nb">iter</span> <span class="mi">90</span><span class="o">/</span><span class="mi">154</span> <span class="o">-</span> <span class="n">loss</span> <span class="mf">1.95007052</span> <span class="o">-</span> <span class="n">samples</span><span class="o">/</span><span class="n">sec</span><span class="p">:</span> <span class="mf">25.18</span>
<span class="mi">2020</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">02</span> <span class="mi">14</span><span class="p">:</span><span class="mi">00</span><span class="p">:</span><span class="mi">31</span><span class="p">,</span><span class="mi">200</span> <span class="n">epoch</span> <span class="mi">1</span> <span class="o">-</span> <span class="nb">iter</span> <span class="mi">105</span><span class="o">/</span><span class="mi">154</span> <span class="o">-</span> <span class="n">loss</span> <span class="mf">1.91979002</span> <span class="o">-</span> <span class="n">samples</span><span class="o">/</span><span class="n">sec</span><span class="p">:</span> <span class="mf">24.46</span>
<span class="mi">2020</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">02</span> <span class="mi">14</span><span class="p">:</span><span class="mi">00</span><span class="p">:</span><span class="mi">51</span><span class="p">,</span><span class="mi">149</span> <span class="n">epoch</span> <span class="mi">1</span> <span class="o">-</span> <span class="nb">iter</span> <span class="mi">120</span><span class="o">/</span><span class="mi">154</span> <span class="o">-</span> <span class="n">loss</span> <span class="mf">1.90456727</span> <span class="o">-</span> <span class="n">samples</span><span class="o">/</span><span class="n">sec</span><span class="p">:</span> <span class="mf">24.38</span>
<span class="mi">2020</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">02</span> <span class="mi">14</span><span class="p">:</span><span class="mi">01</span><span class="p">:</span><span class="mi">11</span><span class="p">,</span><span class="mi">720</span> <span class="n">epoch</span> <span class="mi">1</span> <span class="o">-</span> <span class="nb">iter</span> <span class="mi">135</span><span class="o">/</span><span class="mi">154</span> <span class="o">-</span> <span class="n">loss</span> <span class="mf">1.87982891</span> <span class="o">-</span> <span class="n">samples</span><span class="o">/</span><span class="n">sec</span><span class="p">:</span> <span class="mf">23.49</span>
<span class="mi">2020</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">02</span> <span class="mi">14</span><span class="p">:</span><span class="mi">01</span><span class="p">:</span><span class="mi">31</span><span class="p">,</span><span class="mi">615</span> <span class="n">epoch</span> <span class="mi">1</span> <span class="o">-</span> <span class="nb">iter</span> <span class="mi">150</span><span class="o">/</span><span class="mi">154</span> <span class="o">-</span> <span class="n">loss</span> <span class="mf">1.85678710</span> <span class="o">-</span> <span class="n">samples</span><span class="o">/</span><span class="n">sec</span><span class="p">:</span> <span class="mf">24.27</span>
<span class="mi">2020</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">02</span> <span class="mi">14</span><span class="p">:</span><span class="mi">01</span><span class="p">:</span><span class="mi">36</span><span class="p">,</span><span class="mi">154</span> <span class="o">----------------------------------------------------------------------------------------------------</span>
<span class="mi">2020</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">02</span> <span class="mi">14</span><span class="p">:</span><span class="mi">01</span><span class="p">:</span><span class="mi">36</span><span class="p">,</span><span class="mi">156</span> <span class="n">EPOCH</span> <span class="mi">1</span> <span class="n">done</span><span class="p">:</span> <span class="n">loss</span> <span class="mf">1.8501</span> <span class="o">-</span> <span class="n">lr</span> <span class="mf">0.0199526</span>
<span class="mi">2020</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">02</span> <span class="mi">14</span><span class="p">:</span><span class="mi">01</span><span class="p">:</span><span class="mi">57</span><span class="p">,</span><span class="mi">790</span> <span class="n">DEV</span> <span class="p">:</span> <span class="n">loss</span> <span class="mf">1.5790961980819702</span> <span class="o">-</span> <span class="n">score</span> <span class="mf">0.7859</span>
<span class="mi">2020</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">02</span> <span class="mi">14</span><span class="p">:</span><span class="mi">01</span><span class="p">:</span><span class="mi">58</span><span class="p">,</span><span class="mi">060</span> <span class="n">BAD</span> <span class="n">EPOCHS</span> <span class="p">(</span><span class="n">no</span> <span class="n">improvement</span><span class="p">):</span> <span class="mi">0</span>
<span class="n">saving</span> <span class="n">best</span> <span class="n">model</span>
<span class="mi">2020</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">02</span> <span class="mi">14</span><span class="p">:</span><span class="mi">01</span><span class="p">:</span><span class="mi">58</span><span class="p">,</span><span class="mi">574</span> <span class="o">----------------------------------------------------------------------------------------------------</span>
<span class="mi">2020</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">02</span> <span class="mi">14</span><span class="p">:</span><span class="mi">02</span><span class="p">:</span><span class="mi">20</span><span class="p">,</span><span class="mi">435</span> <span class="n">epoch</span> <span class="mi">2</span> <span class="o">-</span> <span class="nb">iter</span> <span class="mi">15</span><span class="o">/</span><span class="mi">154</span> <span class="o">-</span> <span class="n">loss</span> <span class="mf">1.63866882</span> <span class="o">-</span> <span class="n">samples</span><span class="o">/</span><span class="n">sec</span><span class="p">:</span> <span class="mf">22.17</span>
<span class="mi">2020</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">02</span> <span class="mi">14</span><span class="p">:</span><span class="mi">02</span><span class="p">:</span><span class="mi">40</span><span class="p">,</span><span class="mi">418</span> <span class="n">epoch</span> <span class="mi">2</span> <span class="o">-</span> <span class="nb">iter</span> <span class="mi">30</span><span class="o">/</span><span class="mi">154</span> <span class="o">-</span> <span class="n">loss</span> <span class="mf">1.61095683</span> <span class="o">-</span> <span class="n">samples</span><span class="o">/</span><span class="n">sec</span><span class="p">:</span> <span class="mf">24.17</span>
<span class="mi">2020</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">02</span> <span class="mi">14</span><span class="p">:</span><span class="mi">02</span><span class="p">:</span><span class="mi">59</span><span class="p">,</span><span class="mi">702</span> <span class="n">epoch</span> <span class="mi">2</span> <span class="o">-</span> <span class="nb">iter</span> <span class="mi">45</span><span class="o">/</span><span class="mi">154</span> <span class="o">-</span> <span class="n">loss</span> <span class="mf">1.58390728</span> <span class="o">-</span> <span class="n">samples</span><span class="o">/</span><span class="n">sec</span><span class="p">:</span> <span class="mf">25.28</span>
<span class="mi">2020</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">02</span> <span class="mi">14</span><span class="p">:</span><span class="mi">03</span><span class="p">:</span><span class="mi">20</span><span class="p">,</span><span class="mi">338</span> <span class="n">epoch</span> <span class="mi">2</span> <span class="o">-</span> <span class="nb">iter</span> <span class="mi">60</span><span class="o">/</span><span class="mi">154</span> <span class="o">-</span> <span class="n">loss</span> <span class="mf">1.57619473</span> <span class="o">-</span> <span class="n">samples</span><span class="o">/</span><span class="n">sec</span><span class="p">:</span> <span class="mf">23.40</span>
<span class="mi">2020</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">02</span> <span class="mi">14</span><span class="p">:</span><span class="mi">03</span><span class="p">:</span><span class="mi">39</span><span class="p">,</span><span class="mi">984</span> <span class="n">epoch</span> <span class="mi">2</span> <span class="o">-</span> <span class="nb">iter</span> <span class="mi">75</span><span class="o">/</span><span class="mi">154</span> <span class="o">-</span> <span class="n">loss</span> <span class="mf">1.54124361</span> <span class="o">-</span> <span class="n">samples</span><span class="o">/</span><span class="n">sec</span><span class="p">:</span> <span class="mf">24.58</span>
<span class="mi">2020</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">02</span> <span class="mi">14</span><span class="p">:</span><span class="mi">03</span><span class="p">:</span><span class="mi">59</span><span class="p">,</span><span class="mi">982</span> <span class="n">epoch</span> <span class="mi">2</span> <span class="o">-</span> <span class="nb">iter</span> <span class="mi">90</span><span class="o">/</span><span class="mi">154</span> <span class="o">-</span> <span class="n">loss</span> <span class="mf">1.51295740</span> <span class="o">-</span> <span class="n">samples</span><span class="o">/</span><span class="n">sec</span><span class="p">:</span> <span class="mf">24.33</span>
<span class="mi">2020</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">02</span> <span class="mi">14</span><span class="p">:</span><span class="mi">04</span><span class="p">:</span><span class="mi">19</span><span class="p">,</span><span class="mi">493</span> <span class="n">epoch</span> <span class="mi">2</span> <span class="o">-</span> <span class="nb">iter</span> <span class="mi">105</span><span class="o">/</span><span class="mi">154</span> <span class="o">-</span> <span class="n">loss</span> <span class="mf">1.48691362</span> <span class="o">-</span> <span class="n">samples</span><span class="o">/</span><span class="n">sec</span><span class="p">:</span> <span class="mf">24.75</span>
<span class="mi">2020</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">02</span> <span class="mi">14</span><span class="p">:</span><span class="mi">04</span><span class="p">:</span><span class="mi">38</span><span class="p">,</span><span class="mi">575</span> <span class="n">epoch</span> <span class="mi">2</span> <span class="o">-</span> <span class="nb">iter</span> <span class="mi">120</span><span class="o">/</span><span class="mi">154</span> <span class="o">-</span> <span class="n">loss</span> <span class="mf">1.47600422</span> <span class="o">-</span> <span class="n">samples</span><span class="o">/</span><span class="n">sec</span><span class="p">:</span> <span class="mf">25.34</span>
<span class="mi">2020</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">02</span> <span class="mi">14</span><span class="p">:</span><span class="mi">04</span><span class="p">:</span><span class="mi">58</span><span class="p">,</span><span class="mi">640</span> <span class="n">epoch</span> <span class="mi">2</span> <span class="o">-</span> <span class="nb">iter</span> <span class="mi">135</span><span class="o">/</span><span class="mi">154</span> <span class="o">-</span> <span class="n">loss</span> <span class="mf">1.45883828</span> <span class="o">-</span> <span class="n">samples</span><span class="o">/</span><span class="n">sec</span><span class="p">:</span> <span class="mf">24.23</span>
<span class="mi">2020</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">02</span> <span class="mi">14</span><span class="p">:</span><span class="mi">05</span><span class="p">:</span><span class="mi">19</span><span class="p">,</span><span class="mi">545</span> <span class="n">epoch</span> <span class="mi">2</span> <span class="o">-</span> <span class="nb">iter</span> <span class="mi">150</span><span class="o">/</span><span class="mi">154</span> <span class="o">-</span> <span class="n">loss</span> <span class="mf">1.44938952</span> <span class="o">-</span> <span class="n">samples</span><span class="o">/</span><span class="n">sec</span><span class="p">:</span> <span class="mf">23.09</span>
<span class="mi">2020</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">02</span> <span class="mi">14</span><span class="p">:</span><span class="mi">05</span><span class="p">:</span><span class="mi">23</span><span class="p">,</span><span class="mi">818</span> <span class="o">----------------------------------------------------------------------------------------------------</span>
<span class="mi">2020</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">02</span> <span class="mi">14</span><span class="p">:</span><span class="mi">05</span><span class="p">:</span><span class="mi">23</span><span class="p">,</span><span class="mi">820</span> <span class="n">EPOCH</span> <span class="mi">2</span> <span class="n">done</span><span class="p">:</span> <span class="n">loss</span> <span class="mf">1.4470</span> <span class="o">-</span> <span class="n">lr</span> <span class="mf">0.0199526</span>
<span class="mi">2020</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">02</span> <span class="mi">14</span><span class="p">:</span><span class="mi">05</span><span class="p">:</span><span class="mi">45</span><span class="p">,</span><span class="mi">338</span> <span class="n">DEV</span> <span class="p">:</span> <span class="n">loss</span> <span class="mf">1.3960844278335571</span> <span class="o">-</span> <span class="n">score</span> <span class="mf">0.7994</span>
<span class="mi">2020</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">02</span> <span class="mi">14</span><span class="p">:</span><span class="mi">05</span><span class="p">:</span><span class="mi">45</span><span class="p">,</span><span class="mi">405</span> <span class="n">BAD</span> <span class="n">EPOCHS</span> <span class="p">(</span><span class="n">no</span> <span class="n">improvement</span><span class="p">):</span> <span class="mi">0</span>
<span class="n">saving</span> <span class="n">best</span> <span class="n">model</span>
<span class="mi">2020</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">02</span> <span class="mi">14</span><span class="p">:</span><span class="mi">05</span><span class="p">:</span><span class="mi">49</span><span class="p">,</span><span class="mi">806</span> <span class="o">----------------------------------------------------------------------------------------------------</span>
<span class="mi">2020</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">02</span> <span class="mi">14</span><span class="p">:</span><span class="mi">06</span><span class="p">:</span><span class="mi">11</span><span class="p">,</span><span class="mi">158</span> <span class="n">epoch</span> <span class="mi">3</span> <span class="o">-</span> <span class="nb">iter</span> <span class="mi">15</span><span class="o">/</span><span class="mi">154</span> <span class="o">-</span> <span class="n">loss</span> <span class="mf">1.19971250</span> <span class="o">-</span> <span class="n">samples</span><span class="o">/</span><span class="n">sec</span><span class="p">:</span> <span class="mf">22.72</span>
<span class="mi">2020</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">02</span> <span class="mi">14</span><span class="p">:</span><span class="mi">06</span><span class="p">:</span><span class="mi">31</span><span class="p">,</span><span class="mi">952</span> <span class="n">epoch</span> <span class="mi">3</span> <span class="o">-</span> <span class="nb">iter</span> <span class="mi">30</span><span class="o">/</span><span class="mi">154</span> <span class="o">-</span> <span class="n">loss</span> <span class="mf">1.23841848</span> <span class="o">-</span> <span class="n">samples</span><span class="o">/</span><span class="n">sec</span><span class="p">:</span> <span class="mf">23.22</span>
<span class="mi">2020</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">02</span> <span class="mi">14</span><span class="p">:</span><span class="mi">06</span><span class="p">:</span><span class="mi">52</span><span class="p">,</span><span class="mi">692</span> <span class="n">epoch</span> <span class="mi">3</span> <span class="o">-</span> <span class="nb">iter</span> <span class="mi">45</span><span class="o">/</span><span class="mi">154</span> <span class="o">-</span> <span class="n">loss</span> <span class="mf">1.22383659</span> <span class="o">-</span> <span class="n">samples</span><span class="o">/</span><span class="n">sec</span><span class="p">:</span> <span class="mf">23.46</span>
<span class="mi">2020</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">02</span> <span class="mi">14</span><span class="p">:</span><span class="mi">07</span><span class="p">:</span><span class="mi">12</span><span class="p">,</span><span class="mi">481</span> <span class="n">epoch</span> <span class="mi">3</span> <span class="o">-</span> <span class="nb">iter</span> <span class="mi">60</span><span class="o">/</span><span class="mi">154</span> <span class="o">-</span> <span class="n">loss</span> <span class="mf">1.22022739</span> <span class="o">-</span> <span class="n">samples</span><span class="o">/</span><span class="n">sec</span><span class="p">:</span> <span class="mf">24.40</span>
<span class="mi">2020</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">02</span> <span class="mi">14</span><span class="p">:</span><span class="mi">07</span><span class="p">:</span><span class="mi">33</span><span class="p">,</span><span class="mi">006</span> <span class="n">epoch</span> <span class="mi">3</span> <span class="o">-</span> <span class="nb">iter</span> <span class="mi">75</span><span class="o">/</span><span class="mi">154</span> <span class="o">-</span> <span class="n">loss</span> <span class="mf">1.21155183</span> <span class="o">-</span> <span class="n">samples</span><span class="o">/</span><span class="n">sec</span><span class="p">:</span> <span class="mf">23.51</span>
<span class="mi">2020</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">02</span> <span class="mi">14</span><span class="p">:</span><span class="mi">07</span><span class="p">:</span><span class="mi">51</span><span class="p">,</span><span class="mi">805</span> <span class="n">epoch</span> <span class="mi">3</span> <span class="o">-</span> <span class="nb">iter</span> <span class="mi">90</span><span class="o">/</span><span class="mi">154</span> <span class="o">-</span> <span class="n">loss</span> <span class="mf">1.19975713</span> <span class="o">-</span> <span class="n">samples</span><span class="o">/</span><span class="n">sec</span><span class="p">:</span> <span class="mf">25.92</span>
<span class="mi">2020</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">02</span> <span class="mi">14</span><span class="p">:</span><span class="mi">08</span><span class="p">:</span><span class="mi">10</span><span class="p">,</span><span class="mi">120</span> <span class="n">epoch</span> <span class="mi">3</span> <span class="o">-</span> <span class="nb">iter</span> <span class="mi">105</span><span class="o">/</span><span class="mi">154</span> <span class="o">-</span> <span class="n">loss</span> <span class="mf">1.18502910</span> <span class="o">-</span> <span class="n">samples</span><span class="o">/</span><span class="n">sec</span><span class="p">:</span> <span class="mf">26.38</span>
<span class="mi">2020</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">02</span> <span class="mi">14</span><span class="p">:</span><span class="mi">08</span><span class="p">:</span><span class="mi">31</span><span class="p">,</span><span class="mi">909</span> <span class="n">epoch</span> <span class="mi">3</span> <span class="o">-</span> <span class="nb">iter</span> <span class="mi">120</span><span class="o">/</span><span class="mi">154</span> <span class="o">-</span> <span class="n">loss</span> <span class="mf">1.17209500</span> <span class="o">-</span> <span class="n">samples</span><span class="o">/</span><span class="n">sec</span><span class="p">:</span> <span class="mf">22.15</span>
<span class="mi">2020</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">02</span> <span class="mi">14</span><span class="p">:</span><span class="mi">08</span><span class="p">:</span><span class="mi">52</span><span class="p">,</span><span class="mi">007</span> <span class="n">epoch</span> <span class="mi">3</span> <span class="o">-</span> <span class="nb">iter</span> <span class="mi">135</span><span class="o">/</span><span class="mi">154</span> <span class="o">-</span> <span class="n">loss</span> <span class="mf">1.14961906</span> <span class="o">-</span> <span class="n">samples</span><span class="o">/</span><span class="n">sec</span><span class="p">:</span> <span class="mf">24.02</span>
<span class="mi">2020</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">02</span> <span class="mi">14</span><span class="p">:</span><span class="mi">09</span><span class="p">:</span><span class="mi">11</span><span class="p">,</span><span class="mi">329</span> <span class="n">epoch</span> <span class="mi">3</span> <span class="o">-</span> <span class="nb">iter</span> <span class="mi">150</span><span class="o">/</span><span class="mi">154</span> <span class="o">-</span> <span class="n">loss</span> <span class="mf">1.14153116</span> <span class="o">-</span> <span class="n">samples</span><span class="o">/</span><span class="n">sec</span><span class="p">:</span> <span class="mf">24.99</span>
<span class="mi">2020</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">02</span> <span class="mi">14</span><span class="p">:</span><span class="mi">09</span><span class="p">:</span><span class="mi">15</span><span class="p">,</span><span class="mi">868</span> <span class="o">----------------------------------------------------------------------------------------------------</span>
<span class="mi">2020</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">02</span> <span class="mi">14</span><span class="p">:</span><span class="mi">09</span><span class="p">:</span><span class="mi">15</span><span class="p">,</span><span class="mi">869</span> <span class="n">EPOCH</span> <span class="mi">3</span> <span class="n">done</span><span class="p">:</span> <span class="n">loss</span> <span class="mf">1.1420</span> <span class="o">-</span> <span class="n">lr</span> <span class="mf">0.0199526</span>
<span class="mi">2020</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">02</span> <span class="mi">14</span><span class="p">:</span><span class="mi">09</span><span class="p">:</span><span class="mi">37</span><span class="p">,</span><span class="mi">671</span> <span class="n">DEV</span> <span class="p">:</span> <span class="n">loss</span> <span class="mf">1.3099236488342285</span> <span class="o">-</span> <span class="n">score</span> <span class="mf">0.7939</span>
<span class="mi">2020</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">02</span> <span class="mi">14</span><span class="p">:</span><span class="mi">09</span><span class="p">:</span><span class="mi">37</span><span class="p">,</span><span class="mi">737</span> <span class="n">BAD</span> <span class="n">EPOCHS</span> <span class="p">(</span><span class="n">no</span> <span class="n">improvement</span><span class="p">):</span> <span class="mi">1</span>
<span class="mi">2020</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">02</span> <span class="mi">14</span><span class="p">:</span><span class="mi">09</span><span class="p">:</span><span class="mi">37</span><span class="p">,</span><span class="mi">739</span> <span class="o">----------------------------------------------------------------------------------------------------</span>
<span class="mi">2020</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">02</span> <span class="mi">14</span><span class="p">:</span><span class="mi">10</span><span class="p">:</span><span class="mi">00</span><span class="p">,</span><span class="mi">789</span> <span class="n">epoch</span> <span class="mi">4</span> <span class="o">-</span> <span class="nb">iter</span> <span class="mi">15</span><span class="o">/</span><span class="mi">154</span> <span class="o">-</span> <span class="n">loss</span> <span class="mf">0.97922458</span> <span class="o">-</span> <span class="n">samples</span><span class="o">/</span><span class="n">sec</span><span class="p">:</span> <span class="mf">21.04</span>
<span class="mi">2020</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">02</span> <span class="mi">14</span><span class="p">:</span><span class="mi">10</span><span class="p">:</span><span class="mi">21</span><span class="p">,</span><span class="mi">158</span> <span class="n">epoch</span> <span class="mi">4</span> <span class="o">-</span> <span class="nb">iter</span> <span class="mi">30</span><span class="o">/</span><span class="mi">154</span> <span class="o">-</span> <span class="n">loss</span> <span class="mf">0.99391881</span> <span class="o">-</span> <span class="n">samples</span><span class="o">/</span><span class="n">sec</span><span class="p">:</span> <span class="mf">23.94</span>
<span class="mi">2020</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">02</span> <span class="mi">14</span><span class="p">:</span><span class="mi">10</span><span class="p">:</span><span class="mi">41</span><span class="p">,</span><span class="mi">210</span> <span class="n">epoch</span> <span class="mi">4</span> <span class="o">-</span> <span class="nb">iter</span> <span class="mi">45</span><span class="o">/</span><span class="mi">154</span> <span class="o">-</span> <span class="n">loss</span> <span class="mf">0.96832921</span> <span class="o">-</span> <span class="n">samples</span><span class="o">/</span><span class="n">sec</span><span class="p">:</span> <span class="mf">24.09</span>
<span class="mi">2020</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">02</span> <span class="mi">14</span><span class="p">:</span><span class="mi">11</span><span class="p">:</span><span class="mi">00</span><span class="p">,</span><span class="mi">520</span> <span class="n">epoch</span> <span class="mi">4</span> <span class="o">-</span> <span class="nb">iter</span> <span class="mi">60</span><span class="o">/</span><span class="mi">154</span> <span class="o">-</span> <span class="n">loss</span> <span class="mf">0.96508796</span> <span class="o">-</span> <span class="n">samples</span><span class="o">/</span><span class="n">sec</span><span class="p">:</span> <span class="mf">25.00</span>
<span class="mi">2020</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">02</span> <span class="mi">14</span><span class="p">:</span><span class="mi">11</span><span class="p">:</span><span class="mi">21</span><span class="p">,</span><span class="mi">664</span> <span class="n">epoch</span> <span class="mi">4</span> <span class="o">-</span> <span class="nb">iter</span> <span class="mi">75</span><span class="o">/</span><span class="mi">154</span> <span class="o">-</span> <span class="n">loss</span> <span class="mf">0.97899694</span> <span class="o">-</span> <span class="n">samples</span><span class="o">/</span><span class="n">sec</span><span class="p">:</span> <span class="mf">22.98</span>
</code></pre></div>


</details>

<h5 id="fine-tuning-a-transformers-language-model-with-lmfinetuner">Fine-Tuning a Transformers Language Model with <code>LMFineTuner</code><a class="headerlink" href="#fine-tuning-a-transformers-language-model-with-lmfinetuner" title="Permanent link">&para;</a></h5>
<div class="codehilite"><pre><span></span><code><span class="kn">from</span> <span class="nn">adaptnlp</span> <span class="kn">import</span> <span class="n">LMFineTuner</span>

<span class="c1"># Set output directory to store fine-tuner files and models</span>
<span class="n">OUTPUT_DIR</span> <span class="o">=</span> <span class="s2">&quot;Path/to/model/output/directory&quot;</span> 

<span class="c1"># Set path to train.csv and test.csv datasets, must have a column header labeled &quot;text&quot; to specify data to train language model</span>
<span class="n">train_data_file</span> <span class="o">=</span> <span class="s2">&quot;Path/to/train.csv&quot;</span> 
<span class="n">eval_data_file</span> <span class="o">=</span> <span class="s2">&quot;Path/to/test.csv&quot;</span>

<span class="n">finetuner</span> <span class="o">=</span> <span class="n">LMFineTuner</span><span class="p">(</span>
                        <span class="n">train_data_file</span><span class="o">=</span><span class="n">train_data_file</span><span class="p">,</span>
                        <span class="n">eval_data_file</span><span class="o">=</span><span class="n">eval_data_file</span><span class="p">,</span>
                        <span class="n">model_type</span><span class="o">=</span><span class="s2">&quot;bert&quot;</span><span class="p">,</span>
                        <span class="n">model_name_or_path</span><span class="o">=</span><span class="s2">&quot;bert-base-cased&quot;</span><span class="p">,</span>
                        <span class="n">mlm</span><span class="o">=</span><span class="kc">True</span>
                        <span class="p">)</span>
<span class="c1"># Freeze layers up to the last group of classification layers</span>
<span class="n">finetuner</span><span class="o">.</span><span class="n">freeze</span><span class="p">()</span>

<span class="c1"># Find optimal learning rate with automated learning rate finder</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="n">finetuner</span><span class="o">.</span><span class="n">find_learning_rate</span><span class="p">(</span><span class="n">base_path</span><span class="o">=</span><span class="n">OUTPUT_DIR</span><span class="p">)</span>
<span class="n">finetuner</span><span class="o">.</span><span class="n">freeze</span><span class="p">()</span>

<span class="n">finetuner</span><span class="o">.</span><span class="n">train_one_cycle</span><span class="p">(</span>
                          <span class="n">output_dir</span><span class="o">=</span><span class="n">OUTPUT_DIR</span><span class="p">,</span>
                          <span class="n">learning_rate</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">,</span>
                          <span class="n">per_gpu_train_batch_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
                          <span class="n">num_train_epochs</span><span class="o">=</span><span class="mf">10.0</span><span class="p">,</span>
                          <span class="n">evaluate_during_training</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                          <span class="p">)</span>
</code></pre></div>
                
              
              
                


              
            </article>
          </div>
        </div>
      </main>
      
        
<footer class="md-footer">
  
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid" aria-label="Footer">
        
          <a href="text-generation.html" title="Text Generation" class="md-footer-nav__link md-footer-nav__link--prev" rel="prev">
            <div class="md-footer-nav__button md-icon">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
            </div>
            <div class="md-footer-nav__title">
              <div class="md-ellipsis">
                <span class="md-footer-nav__direction">
                  Previous
                </span>
                Text Generation
              </div>
            </div>
          </a>
        
        
          <a href="training-sequence-classification.html" title="Training Sequence Classification" class="md-footer-nav__link md-footer-nav__link--next" rel="next">
            <div class="md-footer-nav__title">
              <div class="md-ellipsis">
                <span class="md-footer-nav__direction">
                  Next
                </span>
                Training Sequence Classification
              </div>
            </div>
            <div class="md-footer-nav__button md-icon">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4z"/></svg>
            </div>
          </a>
        
      </nav>
    </div>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
        Made with
        <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
          Material for MkDocs
        </a>
      </div>
      
    </div>
  </div>
</footer>
      
    </div>
    
      <script src="../assets/javascripts/vendor.df0def68.min.js"></script>
      <script src="../assets/javascripts/bundle.ba57d267.min.js"></script><script id="__lang" type="application/json">{"clipboard.copy": "Copy to clipboard", "clipboard.copied": "Copied to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.result.placeholder": "Type to start searching", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents"}</script>
      
      <script>
        app = initialize({
          base: "..",
          features: [],
          search: Object.assign({
            worker: "../assets/javascripts/worker/search.5eca75d3.min.js"
          }, typeof search !== "undefined" && search)
        })
      </script>
      
    
  </body>
</html>